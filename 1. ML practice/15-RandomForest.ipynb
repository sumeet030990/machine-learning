{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Problem Statement\n",
    "\n",
    "\"Trips & Travel.Com\" company wants to enable and establish a viable business model to expand the customer base. One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering - Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, the marketing cost was quite high because customers were contacted at random without looking at the available information. The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. However, this time company wants to harness the available data of existing and potential customers to make the marketing expenditure more efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks to Solve :\n",
    "- To predict which customer is more likely to purchase the newly introduced travel package\n",
    "- Which variables are most significant.\n",
    "- Which segment of customers should be targeted more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0        Single            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0        Single            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./resources/csv/15-Travel.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "- Understand the Dataset\n",
    "- Handle Missing Values\n",
    "- Handle Handling Duplicates\n",
    "- Check Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4888 entries, 0 to 4887\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CustomerID                4888 non-null   int64  \n",
      " 1   ProdTaken                 4888 non-null   int64  \n",
      " 2   Age                       4662 non-null   float64\n",
      " 3   TypeofContact             4863 non-null   object \n",
      " 4   CityTier                  4888 non-null   int64  \n",
      " 5   DurationOfPitch           4637 non-null   float64\n",
      " 6   Occupation                4888 non-null   object \n",
      " 7   Gender                    4888 non-null   object \n",
      " 8   NumberOfPersonVisiting    4888 non-null   int64  \n",
      " 9   NumberOfFollowups         4843 non-null   float64\n",
      " 10  ProductPitched            4888 non-null   object \n",
      " 11  PreferredPropertyStar     4862 non-null   float64\n",
      " 12  MaritalStatus             4888 non-null   object \n",
      " 13  NumberOfTrips             4748 non-null   float64\n",
      " 14  Passport                  4888 non-null   int64  \n",
      " 15  PitchSatisfactionScore    4888 non-null   int64  \n",
      " 16  OwnCar                    4888 non-null   int64  \n",
      " 17  NumberOfChildrenVisiting  4822 non-null   float64\n",
      " 18  Designation               4888 non-null   object \n",
      " 19  MonthlyIncome             4655 non-null   float64\n",
      "dtypes: float64(7), int64(7), object(6)\n",
      "memory usage: 763.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Value spelling issues for eg: Female is written as Fe male also in the dataset, we need to fix such type of issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  TypeofContact\n",
      "TypeofContact\n",
      "Self Enquiry       3444\n",
      "Company Invited    1419\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  Occupation\n",
      "Occupation\n",
      "Salaried          2368\n",
      "Small Business    2084\n",
      "Large Business     434\n",
      "Free Lancer          2\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  Gender\n",
      "Gender\n",
      "Male       2916\n",
      "Female     1817\n",
      "Fe Male     155\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  ProductPitched\n",
      "ProductPitched\n",
      "Basic           1842\n",
      "Deluxe          1732\n",
      "Standard         742\n",
      "Super Deluxe     342\n",
      "King             230\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  MaritalStatus\n",
      "MaritalStatus\n",
      "Married      2340\n",
      "Divorced      950\n",
      "Single        916\n",
      "Unmarried     682\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  Designation\n",
      "Designation\n",
      "Executive         1842\n",
      "Manager           1732\n",
      "Senior Manager     742\n",
      "AVP                342\n",
      "VP                 230\n",
      "Name: count, dtype: int64\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "def checkForUniqueColumnValuesForStringDtype():\n",
    "  for columns in df.columns:\n",
    "    if(df[columns].dtype == object):\n",
    "      print('Column Name: ', columns)\n",
    "      print(df[columns].value_counts())\n",
    "      print('===============================')\n",
    "\n",
    "checkForUniqueColumnValuesForStringDtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix Gender Female Spelling issue\n",
    "df['Gender'] = df['Gender'].replace(\"Fe Male\", \"Female\")\n",
    "\n",
    "## In MaritalStatus Single and Unmarried are same so we can club it\n",
    "df['MaritalStatus'] = df['MaritalStatus'].replace('Single', 'Unmarried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  TypeofContact\n",
      "TypeofContact\n",
      "Self Enquiry       3444\n",
      "Company Invited    1419\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  Occupation\n",
      "Occupation\n",
      "Salaried          2368\n",
      "Small Business    2084\n",
      "Large Business     434\n",
      "Free Lancer          2\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  Gender\n",
      "Gender\n",
      "Male      2916\n",
      "Female    1972\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  ProductPitched\n",
      "ProductPitched\n",
      "Basic           1842\n",
      "Deluxe          1732\n",
      "Standard         742\n",
      "Super Deluxe     342\n",
      "King             230\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  MaritalStatus\n",
      "MaritalStatus\n",
      "Married      2340\n",
      "Unmarried    1598\n",
      "Divorced      950\n",
      "Name: count, dtype: int64\n",
      "===============================\n",
      "Column Name:  Designation\n",
      "Designation\n",
      "Executive         1842\n",
      "Manager           1732\n",
      "Senior Manager     742\n",
      "AVP                342\n",
      "VP                 230\n",
      "Name: count, dtype: int64\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "checkForUniqueColumnValuesForStringDtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                         226\n",
      "TypeofContact                25\n",
      "DurationOfPitch             251\n",
      "NumberOfFollowups            45\n",
      "PreferredPropertyStar        26\n",
      "NumberOfTrips               140\n",
      "NumberOfChildrenVisiting     66\n",
      "MonthlyIncome               233\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_with_na = df.isnull().sum()\n",
    "feature_with_na = feature_with_na[feature_with_na > 0]\n",
    "\n",
    "print(feature_with_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Age  DurationOfPitch  NumberOfFollowups  PreferredPropertyStar  \\\n",
      "count  4662.000000      4637.000000        4843.000000            4862.000000   \n",
      "mean     37.622265        15.490835           3.708445               3.581037   \n",
      "std       9.316387         8.519643           1.002509               0.798009   \n",
      "min      18.000000         5.000000           1.000000               3.000000   \n",
      "25%      31.000000         9.000000           3.000000               3.000000   \n",
      "50%      36.000000        13.000000           4.000000               3.000000   \n",
      "75%      44.000000        20.000000           4.000000               4.000000   \n",
      "max      61.000000       127.000000           6.000000               5.000000   \n",
      "\n",
      "       NumberOfTrips  NumberOfChildrenVisiting  MonthlyIncome  \n",
      "count    4748.000000               4822.000000    4655.000000  \n",
      "mean        3.236521                  1.187267   23619.853491  \n",
      "std         1.849019                  0.857861    5380.698361  \n",
      "min         1.000000                  0.000000    1000.000000  \n",
      "25%         2.000000                  1.000000   20346.000000  \n",
      "50%         3.000000                  1.000000   22347.000000  \n",
      "75%         4.000000                  2.000000   25571.000000  \n",
      "max        22.000000                  3.000000   98678.000000  \n"
     ]
    }
   ],
   "source": [
    "column_index_with_na = feature_with_na.index\n",
    "print(df[column_index_with_na].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note that: As means and 50% percentile Quantile is almost near i.e there is not much difference then we can say that we dont have outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling NaN values\n",
    "- For Continous Values we use : MEDIAN\n",
    "- For Categorical features we use : MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['TypeofContact'].fillna(df['TypeofContact'].mode()[0], inplace=True)\n",
    "df['DurationOfPitch'].fillna(df['DurationOfPitch'].median(), inplace=True)\n",
    "df['NumberOfFollowups'].fillna(df['NumberOfFollowups'].median(), inplace=True)\n",
    "df['PreferredPropertyStar'].fillna(df['PreferredPropertyStar'].median(), inplace=True)\n",
    "df['NumberOfTrips'].fillna(df['NumberOfTrips'].median(), inplace=True)\n",
    "df['NumberOfChildrenVisiting'].fillna(df['NumberOfChildrenVisiting'].median(), inplace=True)\n",
    "df['MonthlyIncome'].fillna(df['MonthlyIncome'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                  0\n",
       "ProdTaken                   0\n",
       "Age                         0\n",
       "TypeofContact               0\n",
       "CityTier                    0\n",
       "DurationOfPitch             0\n",
       "Occupation                  0\n",
       "Gender                      0\n",
       "NumberOfPersonVisiting      0\n",
       "NumberOfFollowups           0\n",
       "ProductPitched              0\n",
       "PreferredPropertyStar       0\n",
       "MaritalStatus               0\n",
       "NumberOfTrips               0\n",
       "Passport                    0\n",
       "PitchSatisfactionScore      0\n",
       "OwnCar                      0\n",
       "NumberOfChildrenVisiting    0\n",
       "Designation                 0\n",
       "MonthlyIncome               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0     Unmarried            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0     Unmarried            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unnecessary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cutomer id is not required so we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('CustomerID',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- feature NumberOfPersonVisiting means Total number of persons planning to take the trip with the customer\n",
    "- So feature NumberOfChildrenVisiting ll mean the same \n",
    "\n",
    "\n",
    "i.e. NumberOfPersonVisiting + NumberOfChildrenVisiting ll give us total number of people travelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalPersonVisiting'] = df['NumberOfPersonVisiting']+df['NumberOfChildrenVisiting']\n",
    "\n",
    "df.drop(['NumberOfPersonVisiting','NumberOfChildrenVisiting'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differentiate different Types of Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical Feature =  12\n",
      "Number of Categorical Feature =  6\n",
      "Number of Discrete Feature =  9\n",
      "Number of Continous Feature =  3\n"
     ]
    }
   ],
   "source": [
    "## Numerical features\n",
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O'] \n",
    "## Categorical features\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O'] \n",
    "\n",
    "## Discrete Features: def: A Discrete variable can take only a specific value amongst the set of all possible values or in other words,\n",
    "discrete_features = [feature for feature in num_features if len(df[feature].unique()) <= 25]\n",
    "\n",
    "## Continous Features\n",
    "continous_features = [feature for feature in num_features if feature not in discrete_features]\n",
    "\n",
    "print('Number of Numerical Feature = ', len(num_features))\n",
    "print('Number of Categorical Feature = ', len(cat_features))\n",
    "print('Number of Discrete Feature = ', len(discrete_features))\n",
    "print('Number of Continous Feature = ', len(continous_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the features into independent or say input features and dependent features or say op features\n",
    "X = df.drop('ProdTaken', axis=1)\n",
    "y=df['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat_features = X.select_dtypes(include='object').columns\n",
    "x_num_features = X.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "numeric_tranformer = StandardScaler()\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "  (\"OneHotEncoder\", categorical_transformer, x_cat_features),\n",
    "  (\"StandardScaler\", numeric_tranformer, x_num_features) ## this is not required we are applying just to understand ColumnTranfer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** DecisionTreeClassifier ***********\n",
      "Model Performance\n",
      "Accuracy Score: Train: 1.0000 || Test: 0.9182\n",
      "F1 Score: Train: 1.0000 || Test: 0.7838\n",
      "Precision Score: Train: 1.0000 || Test: 0.8101\n",
      "Recall Score: Train: 1.0000 || Test: 0.7592\n",
      "ROC AUC Score: Train: 1.0000 || Test: 0.8580\n",
      "============================================================\n",
      "\n",
      "\n",
      "*********** Random Forest ***********\n",
      "Model Performance\n",
      "Accuracy Score: Train: 1.0000 || Test: 0.9305\n",
      "F1 Score: Train: 1.0000 || Test: 0.7875\n",
      "Precision Score: Train: 1.0000 || Test: 0.9767\n",
      "Recall Score: Train: 1.0000 || Test: 0.6597\n",
      "ROC AUC Score: Train: 1.0000 || Test: 0.8279\n",
      "============================================================\n",
      "\n",
      "\n",
      "*********** AdaBoostClassifier ***********\n",
      "Model Performance\n",
      "Accuracy Score: Train: 0.8565 || Test: 0.8354\n",
      "F1 Score: Train: 0.4867 || Test: 0.4311\n",
      "Precision Score: Train: 0.7308 || Test: 0.6630\n",
      "Recall Score: Train: 0.3649 || Test: 0.3194\n",
      "ROC AUC Score: Train: 0.6670 || Test: 0.6400\n",
      "============================================================\n",
      "\n",
      "\n",
      "*********** GradientBoostingClassifier ***********\n",
      "Model Performance\n",
      "Accuracy Score: Train: 0.8939 || Test: 0.8589\n",
      "F1 Score: Train: 0.6382 || Test: 0.5208\n",
      "Precision Score: Train: 0.8756 || Test: 0.7732\n",
      "Recall Score: Train: 0.5021 || Test: 0.3927\n",
      "ROC AUC Score: Train: 0.7429 || Test: 0.6824\n",
      "============================================================\n",
      "\n",
      "\n",
      "*********** XgBoost ***********\n",
      "Model Performance\n",
      "Accuracy Score: Train: 0.9995 || Test: 0.9427\n",
      "F1 Score: Train: 0.9986 || Test: 0.8353\n",
      "Precision Score: Train: 1.0000 || Test: 0.9530\n",
      "Recall Score: Train: 0.9973 || Test: 0.7435\n",
      "ROC AUC Score: Train: 0.9986 || Test: 0.8673\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "  \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "  \"Random Forest\": RandomForestClassifier(),\n",
    "  \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "  \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "  \"XgBoost\": XGBClassifier()\n",
    "}\n",
    "\n",
    "for keys,model in models.items():\n",
    "  model.fit(X_train, y_train) ## Train model\n",
    "\n",
    "\n",
    "  ## Make Prediction\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  y_test_pred = model.predict(X_test)\n",
    "\n",
    "  ## Check Training set Performance\n",
    "  model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "  model_train_f1_score = f1_score(y_train, y_train_pred)\n",
    "  model_train_precision_score = precision_score(y_train, y_train_pred)\n",
    "  model_train_recall_score = recall_score(y_train, y_train_pred)\n",
    "  model_train_roc_curve = roc_curve(y_train, y_train_pred)\n",
    "  model_train_roc_auc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "   ## Check Test set Performance\n",
    "  model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "  model_test_f1_score = f1_score(y_test, y_test_pred)\n",
    "  model_test_precision_score = precision_score(y_test, y_test_pred)\n",
    "  model_test_recall_score = recall_score(y_test, y_test_pred)\n",
    "  model_test_roc_curve = roc_curve(y_test, y_test_pred)\n",
    "  model_test_roc_auc_score = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "  print('\\n')\n",
    "  print(f\"*********** {keys} ***********\") ## Name of the model\n",
    "\n",
    "  print(\"Model Performance\")\n",
    "  print(\"Accuracy Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_accuracy,model_test_accuracy))\n",
    "  print(\"F1 Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_f1_score, model_test_f1_score))\n",
    "  print(\"Precision Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_precision_score, model_test_precision_score))\n",
    "  print(\"Recall Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_recall_score, model_test_recall_score))\n",
    "  print(\"ROC AUC Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_roc_auc_score, model_test_roc_auc_score))\n",
    " \n",
    "\n",
    "  print(\"===\"*20)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we can see that Random forest has bit better result then decision tree then we can say go with Random forest for further implementaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparament Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_params={\n",
    "#   \"max_depth\": [5,8,15, None, 20 ],\n",
    "#   \"max_features\": [5,7, \"auto\", 8 ],\n",
    "#   \"min_samples_split\": [2,8,15, 20 ],\n",
    "#   \"n_estimators\": [100,200,500,1000]\n",
    "# }\n",
    "\n",
    "## adaboost not giving good accuracy\n",
    "# adaboost_params={\n",
    "#   \"n_estimators\": [50,60,70,80,90],\n",
    "# }\n",
    "\n",
    "gradientBoost_params = {\n",
    "  \"loss\" :[\"log_loss\", \"exponential\"],\n",
    "  \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "  \"max_features\": [\"sqrt\", \"log2\"],\n",
    "  \"n_estimators\": [100,200,500,1000],\n",
    "  \"max_depth\": [5,8,10,15,None,20 ],\n",
    "  \n",
    "}\n",
    "\n",
    "## Xgboost \n",
    "xgBoost_params = {\n",
    "  \"learning_rate\" :[0.1,0.01],\n",
    "  \"max_depth\": [5,8,12,20,30 ],\n",
    "  \"n_estimators\": [100,200,300],\n",
    "  \"colsample_bytree\": [0.5,0.8,1,0.3,0.4],\n",
    "  \n",
    "}\n",
    "\n",
    "## Model List for HyperParameter Tunning \n",
    "random_cv_models = [\n",
    "  # (\"RF\", RandomForestClassifier(), rf_params),\n",
    "  # (\"AD\", AdaBoostClassifier(), adaboost_params),\n",
    "  (\"GB\", GradientBoostingClassifier(), gradientBoost_params),\n",
    "  (\"Xg\", XGBClassifier(), xgBoost_params)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=200; total time=   5.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=200; total time=   5.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=200; total time=   5.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=500; total time=   6.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=500; total time=   6.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=500; total time=   6.9s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=100; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=1000; total time=   3.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=log2, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=1000; total time=   4.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=100; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=200; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=200; total time=   2.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=200; total time=   6.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=200; total time=   6.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=200; total time=   6.1s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=log2, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=log2, n_estimators=500; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=log2, n_estimators=500; total time=   3.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=200; total time=   2.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   1.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=100; total time=   3.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=100; total time=   3.7s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=200; total time=   2.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=100; total time=   3.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=200; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=log2, n_estimators=500; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=log2, n_estimators=500; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=log2, n_estimators=500; total time=   4.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=200; total time=   5.3s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=log2, n_estimators=200; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=log2, n_estimators=200; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=log2, n_estimators=200; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=200; total time=   6.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, max_features=log2, n_estimators=200; total time=   6.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=log2, n_estimators=1000; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=log2, n_estimators=1000; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=log2, n_estimators=1000; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=log2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=log2, n_estimators=500; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=log2, n_estimators=500; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=log2, n_estimators=500; total time=   3.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=log2, n_estimators=200; total time=   2.9s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=200; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=200; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=log2, n_estimators=200; total time=   3.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=log2, n_estimators=200; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=200; total time=   6.3s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=200; total time=   6.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=200; total time=   6.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.3s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.3s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.7s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=100; total time=   3.7s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=500; total time=   3.9s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   5.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=500; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   6.3s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=log2, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=200; total time=   2.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=log2, n_estimators=500; total time=   2.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=log2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=log2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=200; total time=   2.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   2.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   1.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=1000; total time=   6.9s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=1000; total time=   6.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=log2, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=log2, n_estimators=1000; total time=   7.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=log2, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=log2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=log2, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=200; total time=   6.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=200; total time=   6.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=log2, n_estimators=1000; total time=   4.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=log2, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=log2, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, max_features=sqrt, n_estimators=200; total time=   6.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=log2, n_estimators=500; total time=   0.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=log2, n_estimators=500; total time=   0.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, max_features=log2, n_estimators=500; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=log2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=log2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, max_features=log2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   5.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=log2, n_estimators=500; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=log2, n_estimators=500; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=log2, n_estimators=500; total time=   3.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   5.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=1000; total time=   5.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=log2, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=log2, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, max_features=log2, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=500; total time=   5.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=500; total time=   5.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=sqrt, n_estimators=500; total time=   5.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=log2, n_estimators=1000; total time=   5.9s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=log2, n_estimators=1000; total time=   6.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=log2, n_estimators=1000; total time=   2.7s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=log2, n_estimators=1000; total time=   6.1s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=log2, n_estimators=1000; total time=   6.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=log2, n_estimators=1000; total time=   5.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, max_features=log2, n_estimators=1000; total time=   6.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=sqrt, n_estimators=1000; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=log2, n_estimators=1000; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=log2, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=log2, n_estimators=1000; total time=   4.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=log2, n_estimators=1000; total time=   4.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=log2, n_estimators=500; total time=   4.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=log2, n_estimators=500; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, max_features=log2, n_estimators=500; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=log2, n_estimators=200; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=20, max_features=log2, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=log2, n_estimators=200; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=log2, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=20, max_features=log2, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=20, max_features=log2, n_estimators=500; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, max_features=sqrt, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=500; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=200; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=log2, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=100; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, max_features=log2, n_estimators=100; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.3s[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=20, max_features=sqrt, n_estimators=1000; total time=   3.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, max_features=sqrt, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=log2, n_estimators=500; total time=   5.4s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=log2, n_estimators=500; total time=   5.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, max_features=log2, n_estimators=500; total time=   5.7s\n",
      "--------------Best Params for Model: GradientBoostingClassifier() ----------------\n",
      "{'n_estimators': 500, 'max_features': 'log2', 'max_depth': 8, 'loss': 'log_loss', 'criterion': 'friedman_mse'}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.3s\n",
      "--------------Best Params for Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) ----------------\n",
      "{'n_estimators': 500, 'max_features': 'log2', 'max_depth': 8, 'loss': 'log_loss', 'criterion': 'friedman_mse'}\n",
      "--------------Best Params for Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) ----------------\n",
      "{'n_estimators': 300, 'max_depth': 20, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_params = {}\n",
    "\n",
    "for name, model, params in random_cv_models:\n",
    "  random = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=100, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "  random.fit(X_train, y_train)\n",
    "  model_params[name] = random.best_params_\n",
    "\n",
    "  for mode_name in model_params:\n",
    "    print(f\"--------------Best Params for Model: {model} ----------------\")\n",
    "    print(model_params[mode_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** GradientBoostingClassifier ***********\n",
      "Model Performance\n",
      "Accuracy Score: Train: 1.0000 || Test: 0.9519\n",
      "F1 Score: Train: 1.0000 || Test: 0.8630\n",
      "Precision Score: Train: 1.0000 || Test: 0.9737\n",
      "Recall Score: Train: 1.0000 || Test: 0.7749\n",
      "ROC AUC Score: Train: 1.0000 || Test: 0.8849\n",
      "============================================================\n",
      "\n",
      "\n",
      "*********** XGBClassifier ***********\n",
      "Model Performance\n",
      "Accuracy Score: Train: 1.0000 || Test: 0.9519\n",
      "F1 Score: Train: 1.0000 || Test: 0.8653\n",
      "Precision Score: Train: 1.0000 || Test: 0.9557\n",
      "Recall Score: Train: 1.0000 || Test: 0.7906\n",
      "ROC AUC Score: Train: 1.0000 || Test: 0.8908\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "  # \"Random Forest\": RandomForestClassifier(n_estimators= 500, min_samples_split= 2, max_features= 8, max_depth= None),\n",
    "  # \"AdaBoostClassifier\": AdaBoostClassifier(n_estimators=80), ## not using as accuracy is low\n",
    "  \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators= 1000, max_features= 'sqrt', max_depth= 8, loss= 'log_loss', criterion= 'friedman_mse'),\n",
    "  \"XGBClassifier\": XGBClassifier(n_estimators= 300, max_depth= 12, learning_rate= 0.1, colsample_bytree= 1)\n",
    "}\n",
    "\n",
    "for keys,model in models.items():\n",
    "  model.fit(X_train, y_train) ## Train model\n",
    "\n",
    "\n",
    "  ## Make Prediction\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  y_test_pred = model.predict(X_test)\n",
    "\n",
    "  ## Check Training set Performance\n",
    "  model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "  model_train_f1_score = f1_score(y_train, y_train_pred)\n",
    "  model_train_precision_score = precision_score(y_train, y_train_pred)\n",
    "  model_train_recall_score = recall_score(y_train, y_train_pred)\n",
    "  model_train_roc_curve = roc_curve(y_train, y_train_pred)\n",
    "  model_train_roc_auc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "   ## Check Test set Performance\n",
    "  model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "  model_test_f1_score = f1_score(y_test, y_test_pred)\n",
    "  model_test_precision_score = precision_score(y_test, y_test_pred)\n",
    "  model_test_recall_score = recall_score(y_test, y_test_pred)\n",
    "  model_test_roc_curve = roc_curve(y_test, y_test_pred)\n",
    "  model_test_roc_auc_score = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "  print('\\n')\n",
    "  print(f\"*********** {keys} ***********\") ## Name of the model\n",
    "\n",
    "  print(\"Model Performance\")\n",
    "  print(\"Accuracy Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_accuracy,model_test_accuracy))\n",
    "  print(\"F1 Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_f1_score, model_test_f1_score))\n",
    "  print(\"Precision Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_precision_score, model_test_precision_score))\n",
    "  print(\"Recall Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_recall_score, model_test_recall_score))\n",
    "  print(\"ROC AUC Score: Train: {:.4f} || Test: {:.4f}\". format(model_train_roc_auc_score, model_test_roc_auc_score))\n",
    " \n",
    "\n",
    "  print(\"===\"*20)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "\n",
    "## PLot ROC AUC Curve\n",
    "plt.figure()\n",
    "\n",
    "## Add the model to the list you want to view on the ROC plot\n",
    "auc_models = [\n",
    "  {\n",
    "    'label': 'Random Forest Classifier',\n",
    "    'model': RandomForestClassifier(n_estimators= 500, min_samples_split= 2, max_features= 8, max_depth= None),\n",
    "    'auc': 0.8404\n",
    "  }, \n",
    "  # {\n",
    "  #   'label': 'ADA BoostClassifier',\n",
    "  #   'model':  AdaBoostClassifier(n_estimators=80),\n",
    "  #   'auc': 0.6049\n",
    "  # },\n",
    "  {\n",
    "    'label': 'GradientBoostingClassifier',\n",
    "    'model': GradientBoostingClassifier(n_estimators= 1000, max_features= 'sqrt', max_depth= 8, loss= 'log_loss', criterion= 'friedman_mse'),\n",
    "    'auc': 0.8947\n",
    "  }, \n",
    "  {\n",
    "    'label': 'XGBClassifier',\n",
    "    'model': XGBClassifier(n_estimators= 300, max_depth= 12, learning_rate= 0.1, colsample_bytree= 1),\n",
    "    'auc': 0.8908\n",
    "  }, \n",
    "]\n",
    "\n",
    "## create a loop through all the models\n",
    "for algo in auc_models:\n",
    "  model = algo['model'] # select the model\n",
    "  model.fit(X_train, y_train) # train the model\n",
    "  #Comput False positive rate, True positive rate\n",
    "  fpr,tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "\n",
    "  #Calculate Area under the curve to display on the plot\n",
    "  plt.plot(fpr, tpr, label = '%s ROC (area = %0.2f)' % (algo['label'], algo['auc']))\n",
    "\n",
    "# Customize setting for plot\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "\n",
    "plt.xlabel(\"1- Specificity(False Positive Rate)\")\n",
    "plt.ylabel(\"Sensitivity(True Positive Rate)\")\n",
    "plt.title(\"Reciever Operating Characeteristics\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
